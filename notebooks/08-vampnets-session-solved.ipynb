{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAMPnets\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" title='This work is licensed under a Creative Commons Attribution 4.0 International License.' align=\"right\"/></a><br><br>\n",
    "\n",
    "In this session we will see an example of how to use VAMPnets to extract a coarse-grained model from raw data using a n unsupervised deep learning approach. We will load data from a 2D toy model with xxx states, and build and train a neural network that assigns each datapoint to a separate state, and finally visualize the information we extracted from the dataset. \n",
    "After this, we will follow the same process to analyse a trajectory of the molecule Alanine Dipeptide, since it is a 30D system whose dynamics can be easily visualized in a 2D space.\n",
    "\n",
    "\n",
    "<a id=\"ref-1\" href=\"https://www.nature.com/articles/s41467-017-02388-1\">Here</a> you can find literature on the used method.\n",
    "\n",
    "**Remember**:\n",
    "- to run the currently highlighted cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- to get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the required packages\n",
    "\n",
    "In case you haven't installed pytorch: [Installation instructions](https://pytorch.org/get-started/locally/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:00:18.448464Z",
     "start_time": "2022-02-17T10:00:16.828959Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mdshare\n",
    "import pyemma\n",
    "import deeptime as dt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from deeptime.plots import plot_implied_timescales\n",
    "from deeptime.util.validation import implied_timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:00:18.454416Z",
     "start_time": "2022-02-17T10:00:18.450757Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is optional if you have CUDA/GPU support\n",
    "device = torch.device(\"cuda\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.set_num_threads(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guided example: 2D toy model\n",
    "We start by loading the data for the 2D model by using the package `mdshare`. The `fetch` function fetches the data from our servers. **Do not use `mdshare` for your own data!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:00:18.888328Z",
     "start_time": "2022-02-17T10:00:18.456161Z"
    }
   },
   "outputs": [],
   "source": [
    "file = mdshare.fetch(\"hmm-doublewell-2d-100k.npz\", working_directory=\"data\")\n",
    "with np.load(file) as fh:\n",
    "    data = fh[\"trajectory\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we want to visualize how the datas are distributed in the 2D space.\n",
    "\n",
    "#### Exercise\n",
    "Plot the density of the data using a function from the `pyemma` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:00:19.481092Z",
     "start_time": "2022-02-17T10:00:18.890480Z"
    }
   },
   "outputs": [],
   "source": [
    "pyemma.plots.plot_density(data[:,0], data[:,1]) ##FIXME\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter selection\n",
    "The next step is a bit tricky, as hyperparameter selection requires some experience to be done correctly. We provided some default values that will allow for a smooth training of our model. The meaning of every hyperparameter is explained in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:20.118868Z",
     "start_time": "2022-02-17T10:07:20.112073Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tau, how much is the timeshift of the two datasets\n",
    "tau = 1\n",
    "\n",
    "# Batch size for Stochastic Gradient descent\n",
    "batch_size = 3000\n",
    "\n",
    "# Which trajectory points percentage is used as validation\n",
    "val_ratio = 0.1\n",
    "\n",
    "# How many hidden layers the network has\n",
    "network_depth = 4\n",
    "\n",
    "# \"Width\" of every layer\n",
    "layer_width = 20\n",
    "\n",
    "# Learning rate used for the ADAM optimizer\n",
    "learning_rate = 5e-3\n",
    "\n",
    "# How many output states the network has\n",
    "output_size = 2\n",
    "\n",
    "# List of nodes of each layer\n",
    "nodes = [data.shape[1]] + [layer_width for _ in range(network_depth)] + [output_size]\n",
    "\n",
    "# Iteration over the training set in the fitting process;\n",
    "# basically how many iterations our training algorithm will do\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "Now we can to prepare our data so that it can be used for training our VAMPnets model. We want two arrays made of coupled datapoints, which are selected from the main trajectory at indexes $i, i+\\tau$. We want the two trajectories to be shuffled, but to maintain the correspondence between the non-time-lagged and the time-lagged datapoints. Finally, we want to split our data into training set and validation set, the former being used for training the algorithm, and the latter being necessary to test whether the network is overfitting ( = the resulting transformation works only on the training set but not on data from the same distribution).\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:20.833305Z",
     "start_time": "2022-02-17T10:07:20.829666Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dt.util.data.TrajectoryDataset(lagtime=tau, trajectory=data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:21.087694Z",
     "start_time": "2022-02-17T10:07:21.061429Z"
    }
   },
   "outputs": [],
   "source": [
    "n_val = int(len(dataset)*val_ratio)\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [len(dataset) - n_val, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:21.261012Z",
     "start_time": "2022-02-17T10:07:21.247655Z"
    }
   },
   "outputs": [],
   "source": [
    "from deeptime.util.torch import MLP\n",
    "lobe = MLP(units=nodes, nonlinearity=nn.ELU, output_nonlinearity=nn.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:22.043651Z",
     "start_time": "2022-02-17T10:07:22.040554Z"
    }
   },
   "outputs": [],
   "source": [
    "vampnet = dt.decomposition.deep.VAMPNet(lobe=lobe, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:07:22.705168Z",
     "start_time": "2022-02-17T10:07:22.702307Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(val_data, batch_size=len(val_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:12:19.176451Z",
     "start_time": "2022-02-17T10:07:23.393483Z"
    }
   },
   "outputs": [],
   "source": [
    "model = vampnet.fit(loader_train, n_epochs=nb_epoch, validation_loader=loader_val, progress=tqdm).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model validation\n",
    "\n",
    "When the previous cell will finish running, we have successfully (ðŸ¤ž) trained our VAMPnets. We can plot the training information to visualize how well our training proceeded, and by plotting both training and validation information we can make sure that our model didn't overfit. Before running the next cell, consider that the our network's training and validation scores should converge to a value slightly lower than $2$, since the score is calculated as the norm of the singular values of the estimated Koopman operator. We only have 2 output nodes and the largest singular value is always $=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:12:19.887907Z",
     "start_time": "2022-02-17T10:12:19.179367Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(*vampnet.train_scores.T, label='training')\n",
    "plt.loglog(*vampnet.validation_scores.T, label='validation')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('score')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally reap the results of our work: if the network was properly trained it should automatically separate the two wells in our system. We can verify this hypothesis by first transforming our dataset with the network using the `model.predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:17:25.523840Z",
     "start_time": "2022-02-17T10:17:25.250759Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_data = model.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize to which states the network assigns every point; we do so in the following cell by calculating to which state every datapoint is most likely to be assigned by the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:17:29.444753Z",
     "start_time": "2022-02-17T10:17:26.202519Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(*data.T, c=transformed_data[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are looking at an orange and a blue ball, your network reached its optimal state during the training. \n",
    "\n",
    "We can further analyze the output of the network by visualizing the decision landscape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:17:33.209614Z",
     "start_time": "2022-02-17T10:17:32.789421Z"
    }
   },
   "outputs": [],
   "source": [
    "xmax = np.max(np.abs(data[:, 0]))\n",
    "ymin = np.min(data[:, 1])\n",
    "ymax = np.max(data[:, 1])\n",
    "grid = np.meshgrid(np.linspace(-xmax-1, xmax+1, 150), np.linspace(ymin-1, ymax+1, 50))\n",
    "xy = np.dstack(grid).reshape(-1, 2)\n",
    "z = model.transform(xy)[:,0]\n",
    "\n",
    "cb = plt.contourf(grid[0], grid[1], z.reshape(grid[0].shape), levels=15, cmap='coolwarm')\n",
    "plt.colorbar(cb);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a very simple system, the network should enforce a very sharp classification, with most of the points belonging to either `state 1` or `state 2`, with only a few points in between having a mixed value.\n",
    "\n",
    "As a last step, we can verify that the network preserves the slow information in the system by plotting the implied timescales present in our transformed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T10:17:43.337174Z",
     "start_time": "2022-02-17T10:17:36.340910Z"
    }
   },
   "outputs": [],
   "source": [
    "lagtimes = np.arange(1, 11)\n",
    "its = implied_timescales([dt.decomposition.VAMP(lagtime=lag, observable_transform=model).fit(data).fetch_model() for lag in lagtimes])\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "plot_implied_timescales(its, ax=axes)\n",
    "axes.set_yscale('log')\n",
    "axes.set_xlabel('lagtime (steps)')\n",
    "axes.set_ylabel('timescale (steps)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-on session: Alanine Dipeptide\n",
    "In the following three cells, you are given the loading function for the alanine-dipeptide trajectories (along with its 2 dihedral values), a plot that shows how to visualize information about the molecule using the dihedral data, and a set of hyperparameters. Build and train a network that classifies alanine samples, and set the number of epochs so that your network converges to a stable score. Plot your results and confront them to the provided examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 1: Loading\n",
    "**NOTE: do NOT use the dihedral information for the training! It would be easier to do so, but the interesting aspect of this exercise lies in seeing how easily the network extracts a low level representation from a highly dimensional space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:42:23.006552Z",
     "start_time": "2022-02-17T09:42:22.940646Z"
    }
   },
   "outputs": [],
   "source": [
    "ala_coords_file = mdshare.fetch(\n",
    "    \"alanine-dipeptide-3x250ns-heavy-atom-positions.npz\", working_directory=\"data\"\n",
    ")\n",
    "with np.load(ala_coords_file) as fh:\n",
    "    data = fh[\"arr_0\"]\n",
    "\n",
    "dihedral_file = mdshare.fetch(\n",
    "    \"alanine-dipeptide-3x250ns-backbone-dihedrals.npz\", working_directory=\"data\"\n",
    ")\n",
    "with np.load(dihedral_file) as fh:\n",
    "    dihedral = fh[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 2: Visualization\n",
    "Since the dynamics of the molecule are completely described by its position in the dihedral plane, we can use these two variables every time we need to pass an x-axis and y-axis to a plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:42:27.352272Z",
     "start_time": "2022-02-17T09:42:26.990397Z"
    }
   },
   "outputs": [],
   "source": [
    "pyemma.plots.plot_density(*dihedral.T, cmap=\"viridis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell 3: Hyperparameters\n",
    "The `nb_epochs` variable is missing a value. Experiment with the training and find a number of epochs that ensures that your network will converge every time you train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:51:17.283372Z",
     "start_time": "2022-02-17T09:51:17.277646Z"
    }
   },
   "outputs": [],
   "source": [
    "tau = 1\n",
    "\n",
    "batch_size = 10000\n",
    "\n",
    "train_ratio = 0.9\n",
    "\n",
    "network_depth = 6\n",
    "\n",
    "layer_width = 30\n",
    "\n",
    "learning_rate = 5e-3\n",
    "\n",
    "output_size = 6\n",
    "\n",
    "nodes = [data.shape[1]] + [layer_width for _ in range(network_depth)] + [output_size]\n",
    "\n",
    "nb_epoch = 30## FIXME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:42:30.220102Z",
     "start_time": "2022-02-17T09:42:30.206208Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = dt.util.data.TrajectoryDataset(lagtime=tau, trajectory=data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:42:31.123941Z",
     "start_time": "2022-02-17T09:42:31.078446Z"
    }
   },
   "outputs": [],
   "source": [
    "n_val = int(len(dataset)*val_ratio)\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [len(dataset) - n_val, n_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:51:14.732232Z",
     "start_time": "2022-02-17T09:51:14.724872Z"
    }
   },
   "outputs": [],
   "source": [
    "from deeptime.util.torch import MLP\n",
    "lobe = MLP(units=nodes, nonlinearity=nn.ELU, output_nonlinearity=nn.Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:51:15.169200Z",
     "start_time": "2022-02-17T09:51:15.163638Z"
    }
   },
   "outputs": [],
   "source": [
    "vampnet = dt.decomposition.deep.VAMPNet(lobe=lobe, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:51:19.257364Z",
     "start_time": "2022-02-17T09:51:19.252728Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(val_data, batch_size=len(val_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:57:57.168327Z",
     "start_time": "2022-02-17T09:51:20.226057Z"
    }
   },
   "outputs": [],
   "source": [
    "model = vampnet.fit(loader_train, n_epochs=nb_epoch, validation_loader=loader_val, progress=tqdm).fetch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:00.304365Z",
     "start_time": "2022-02-17T09:57:59.706153Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.loglog(*vampnet.train_scores.T, label='training')\n",
    "plt.loglog(*vampnet.validation_scores.T, label='validation')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('score')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:07.768794Z",
     "start_time": "2022-02-17T09:58:06.620620Z"
    }
   },
   "outputs": [],
   "source": [
    "transformed_data = model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:37.567956Z",
     "start_time": "2022-02-17T09:58:08.445781Z"
    }
   },
   "outputs": [],
   "source": [
    "lagtimes = np.arange(1, 11)\n",
    "its = implied_timescales([dt.decomposition.VAMP(lagtime=lag, observable_transform=model).fit(data).fetch_model() for lag in lagtimes])\n",
    "fig, axes = plt.subplots(1, 1, figsize=(6, 4))\n",
    "\n",
    "plot_implied_timescales(its, ax=axes)\n",
    "axes.set_yscale('log')\n",
    "axes.set_xlabel('lagtime (steps)')\n",
    "axes.set_ylabel('timescale (steps)')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:55.913229Z",
     "start_time": "2022-02-17T09:58:37.570595Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(output_size):\n",
    "    plt.scatter(*dihedral.T, c=transformed_data[:,i], s=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:55.921705Z",
     "start_time": "2022-02-17T09:58:55.915544Z"
    }
   },
   "outputs": [],
   "source": [
    "colorcode = np.argmax(transformed_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T09:58:59.401302Z",
     "start_time": "2022-02-17T09:58:55.925013Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(*dihedral.T, c=colorcode, s=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your network code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are done, the results should look like this:\n",
    "\n",
    "#### Dihedral space separation\n",
    "<img style=\"float: left;\" src=\"./img/space_division.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output values for each node\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state1.png\"/>\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state2.png\"/>\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state3.png\"/>\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state4.png\"/>\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state5.png\"/>\n",
    "<img  style=\"float: left;\" src=\"./img/prob_state6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timescales\n",
    "<img style=\"float: left;\" src=\"./img/timescales.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
